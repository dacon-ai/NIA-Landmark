{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "from absl import app\n",
    "from absl import flags\n",
    "\n",
    "import tensorflow as tf\n",
    "import functools\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from pathlib import Path\n",
    "from model.model import GeMPoolingLayer, DelfArcFaceModel, ArcFaceLayer\n",
    "from utils.preprocessing import CreateDataset\n",
    "\n",
    "strategy = tf.distribute.MirroredStrategy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "batch_size = 32\n",
    "image_size = 224\n",
    "learning_rate = 1e-4  # should be smaller than training on single GPU\n",
    "feature_size = 2048  # Embedding size before the output layer\n",
    "save_interval = 1000\n",
    "\n",
    "# ArcFace params\n",
    "margin = 0.1  # DELG used 0.1, original ArcFace paper used 0.5. When margin is 0, it should be the same as doing a normal softmax but with embedding and weight normalised.\n",
    "logit_scale = int(math.sqrt(feature_size))\n",
    "\n",
    "# GeM params\n",
    "gem_p = 3.\n",
    "train_p = False  # whether to learn gem_p or not\n",
    "\n",
    "data_dir = \"/home/ubuntu/Dacon/jin/NIA\"\n",
    "\n",
    "training_csv_path = os.path.join(data_dir, \"train.csv\")\n",
    "train_csv = pd.read_csv(str(training_csv_path))\n",
    "num_samples = len(train_csv[\"id\"].tolist())\n",
    "unique_landmark_ids = train_csv[\"landmark_id\"].unique().tolist()\n",
    "unique_landmark_ids = tf.convert_to_tensor(unique_landmark_ids, dtype=tf.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = num_samples\n",
    "\n",
    "BATCH_SIZE_PER_REPLICA = 128\n",
    "GLOBAL_BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync\n",
    "\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = \"/home/ubuntu/Dacon/jin/NIA/checkpoint/\"\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "train_tf_records_dir = \"/home/ubuntu/Dacon/jin/NIA/tfrecords/train-*\"\n",
    "test_tf_records_dir = \"/home/ubuntu/Dacon/jin/NIA/tfrecords/validation-*\"\n",
    "\n",
    "with strategy.scope():\n",
    "    training_set = CreateDataset(train_tf_records_dir, unique_landmark_ids).batch(GLOBAL_BATCH_SIZE)\n",
    "    train_dist_dataset = strategy.experimental_distribute_dataset(training_set)\n",
    "\n",
    "    test_set = CreateDataset(test_tf_records_dir, unique_landmark_ids).batch(GLOBAL_BATCH_SIZE)\n",
    "    test_dist_dataset = strategy.experimental_distribute_dataset(test_set)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/landmark/lib/python3.7/site-packages/tensorflow/python/data/ops/multi_device_iterator_ops.py:601: get_next_as_optional (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Iterator.get_next_as_optional()` instead.\n",
      "INFO:tensorflow:batch_all_reduce: 217 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 217 all-reduces with algorithm = nccl, num_packs = 1\n"
     ]
    }
   ],
   "source": [
    "     with strategy.scope():\n",
    "        model = DelfArcFaceModel(\n",
    "                input_shape=(image_size, image_size, 3), n_classes=len(unique_landmark_ids), margin=margin, logit_scale=logit_scale,\n",
    "                p=gem_p, train_p=train_p, feature_size=feature_size\n",
    "            )\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "        loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.NONE)\n",
    "        train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "        train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "        test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "        test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')\n",
    "        checkpoint = tf.train.Checkpoint(optimizer=optimizer, model=model)\n",
    "\n",
    "        def compute_loss(labels, predictions):\n",
    "            per_example_loss = loss_object(labels, predictions)\n",
    "            return tf.nn.compute_average_loss(per_example_loss, global_batch_size=GLOBAL_BATCH_SIZE)\n",
    "\n",
    "        def train_step(images, labels):\n",
    "            with tf.GradientTape() as tape:\n",
    "                # training=True is only needed if there are layers with different\n",
    "                # behavior during training versus inference (e.g. Dropout).\n",
    "                predictions = model((images, labels), training=True)\n",
    "\n",
    "                loss = compute_loss(labels, predictions)\n",
    "            gradients = tape.gradient(loss, model.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "            train_loss(loss * strategy.num_replicas_in_sync)\n",
    "            train_accuracy(labels, predictions)\n",
    "            return loss\n",
    "\n",
    "        def test_step(images, labels):\n",
    "            # training=False is only needed if there are layers with different\n",
    "            # behavior during training versus inference (e.g. Dropout).\n",
    "            predictions = model(images, training=False)\n",
    "            t_loss = loss_object(labels, predictions)\n",
    "\n",
    "            test_loss(t_loss)\n",
    "            test_accuracy(labels, predictions)    \n",
    "\n",
    "        @tf.function    \n",
    "        def distributed_train_step(images, labels):\n",
    "            per_replica_losses = strategy.run(train_step, args=(images, labels,))\n",
    "            return strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses,\n",
    "                               axis=None)\n",
    "\n",
    "        @tf.function\n",
    "        def distributed_test_step(images, labels):\n",
    "            return strategy.run(test_step, args=(images, labels,))\n",
    "\n",
    "        for epoch in range(EPOCHS):\n",
    "            # 훈련 루프\n",
    "            total_loss = 0.0\n",
    "            num_batches = 0\n",
    "        \n",
    "    with tqdm(total=int(num_samples)*0.8) as pbar:\n",
    "        template = 'Epoch {}, Training, Loss: {:.4f}, Accuracy: {:.4f}'\n",
    "            for x, y in train_dist_dataset:\n",
    "              total_loss += distributed_train_step(x, y)\n",
    "              num_batches += 1\n",
    "              pbar.set_description(template.format(epoch + 1, train_loss.result(), train_accuracy.result() * 100))              \n",
    "            train_loss = total_loss / num_batches\n",
    "\n",
    "            \n",
    "\n",
    "            # 테스트 루프\n",
    "            for x, y in test_dist_dataset:\n",
    "              distributed_test_step(x, y)\n",
    "\n",
    "            if epoch % 1 == 0:\n",
    "              checkpoint.save(checkpoint_prefix)\n",
    "\n",
    "            template = (\"에포크 {}, 손실: {}, 정확도: {}, 테스트 손실: {}, \"\n",
    "                        \"테스트 정확도: {}\")\n",
    "            print (template.format(epoch+1, train_loss,\n",
    "                                   train_accuracy.result()*100, test_loss.result(),\n",
    "                                   test_accuracy.result()*100))\n",
    "\n",
    "            test_loss.reset_states()\n",
    "            train_accuracy.reset_states()\n",
    "            test_accuracy.reset_states()          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "landmark",
   "language": "python",
   "name": "landmark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
